# Simplify-SentimentJP
# 読みやすさ強化による日本語感情分類：平易化利用の検討

## 背景と目的  
本研究は、**日本語文章の感情（極性）分類**タスクにおいて、**平易化（simplification）** を用いることで分類性能を改善できるかを検証することを目的とする。  
主仮説は以下の通り：  
> 平易化により冗長・曖昧・ノイズ要素が除去され、モデル学習が容易になり、三値（ネガティブ／中立／ポジティブ）分類において平易化文のみを使ったモデルが、原文のみを使ったモデルより優れた性能を示すかもしれない。

さらに、**原文＋平易化文併用（Concat）** や **表記正規化処理** を含む条件を設け、それぞれの利点・欠点を比較・分析する。

## データとラベル変換  
- 使用データ：**WRIME v2**  
- 元の極性ラベル（−2, −1, 0, +1, +2）を次のように三値分類用に変換：  
  - neg: {−2, −1}  
  - neu: {0}  
  - pos: {+1, +2}  
- 極性参照視点：通常は “reader（読者視点）” を基準とし、補助実験で “writer 視点” とのズレを検討  
- データ分割：著者単位で層化分割を行い、リークを防止。三クラス比をできるだけ維持。

## 実験条件（モデル入力パターン）  

| 条件名 | 入力データ | 意図・目的 |
|---|---|---|
| Orig | 原文そのまま | ベースライン |
| Simp | 平易化文のみ | 平易化の効果を直接評価 |
| Concat | 原文 + 平易化文（同ラベル） | データ拡張・情報併用の効果を検討 |
| Noise-norm | 表記ゆれ正規化等の軽処理 | 平易化・正規化効果の切り分けを可能にする比較条件 |

- 平易化の生成には LLM を用い、**意味保持**と**極性保持**を意図的に指示  
- 品質フィルタとして以下を適用：  
  1. **BERTScore** による意味保持チェック  
  2. 原文と平易化文での極性不一致サンプルを除外またはフラグ付け  

## モデル設定と学習  
- 基盤モデル：**東北大学版日本語 BERT**（例：`tohoku-nlp/bert-base-japanese` 系列）  
- 分類ヘッド：CLS 表現 → 全結合 → 3 クラス出力  
- 損失関数：加重クロスエントロピー（クラス不均衡対応）  
- 学習設定：学習率、バッチサイズ、エポック数、早期終了、複数乱数シードを用いた平均化  
- 再現性：乱数シードを複数設定し、平均結果と **95% 信頼区間** を明記

## 評価指標と分析方法  
- **主評価指標**：Macro-F1  
- **補助指標**：Accuracy、クラス別 F1、混同行列  
- **意味保持評価**：BERTScore    
- **極性不一致率**：原文と平易化文でのラベル一致率  
- **統計的検定**：McNemar 検定またはブートストラップ法によるモデル間差の有意性確認  
- **層別分析**：投稿長、語彙難易度、表記ノイズ量などの属性別性能比較  
- **失敗例抽出**：Simp で性能が落ちたケースを収集して、改善指針を得る

## 想定される知見・示唆  
1. 平易化（Simp）は冗長表現・曖昧表現・ノイズ要素が多い文で有効に働く可能性。  
2. ただし、皮肉・含意・程度副詞・否定表現などを簡約中に失うと性能低下を招く可能性。  
3. Concat 条件は、品質管理が十分なら最も性能向上が得られるが、ノイズ混入で逆効果となりうる。  
4. Noise-norm 条件を導入することで、簡約の効果が表記正規化不足ではなく内容の変化によるものかを検証できる。  

## 実験の進行手順（概要）  
1. WRIME v2 の読み込み → 三値変換 → 分割  
2. Noise-norm バージョンを作成  
3. 平易化生成と品質フィルタ処理  
4. 各条件（Orig / Simp / Concat / Noise-norm）でモデル学習（複数乱数シード）  
5. 評価指標計算および差の有意性検定  
6. 層別分析・失敗例解析  
7. 結論・示唆・限界・将来展望のまとめ
